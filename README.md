# üöÄ LLM Context Builder - √âdition Desktop

Une application de bureau compl√®te pour pr√©parer, analyser et interagir avec vos projets de code via des LLMs. Cr√©ez un contexte de projet s√©curis√© et optimis√©, et dialoguez avec une IA gr√¢ce √† une bo√Æte √† outils de d√©veloppement int√©gr√©e.

> üõ°Ô∏è **S√©curit√© avant tout** : Cet outil int√®gre un puissant m√©canisme de d√©tection et de masquage des secrets (cl√©s API, mots de passe, tokens) pour pr√©venir toute fuite d'informations sensibles vers les mod√®les de langage.

![Aper√ßu de l'interface](https://github.com/user-attachments/assets/e2816992-9967-403a-b8d6-3df6e618a0e)

## ‚ú® Fonctionnalit√©s Cl√©s

- **üñ•Ô∏è Application de Bureau Native** : Interface utilisateur web moderne (`Flask` + `pywebview`) encapsul√©e dans une application de bureau autonome pour une exp√©rience fluide et int√©gr√©e.
- **üß† Scan de Projet Intelligent** : Analyse les r√©pertoires locaux en respectant automatiquement les r√®gles `.gitignore` et en filtrant les fichiers non pertinents (binaires, logs, etc.).
- **üîê Masquage de Secrets Avanc√©** : Utilise `detect-secrets` et des expressions r√©guli√®res pour identifier et masquer les informations sensibles avant la g√©n√©ration du contexte.
- **üîÑ Persistance de S√©lection de Fichiers** : Sauvegarde automatiquement votre s√©lection de fichiers et permet de la restaurer en un clic lors de la prochaine ouverture du projet. Identifie et met en √©vidence les nouveaux fichiers ajout√©s depuis la derni√®re session.
- **üíæ Gestion de Conversations** : Sauvegardez, chargez, dupliquez et g√©rez vos sessions de chat avec **g√©n√©ration automatique de titre par IA**. Le syst√®me inclut le contexte du projet et un **m√©canisme de verrouillage** pour un travail multi-instances s√©curis√©.
- **üß∞ Toolbox D√©veloppeur Augment√©** : Un puissant assistant IA int√©gr√© avec deux modes :
    - **Mode API** : Un client de chat direct avec votre LLM configur√© (supporte OpenAI et Ollama), avec gestion de l'historique, streaming, et export des conversations.
    - **Mode Navigateur** : Pilote une fen√™tre de navigateur int√©gr√©e pour interagir avec des services comme ChatGPT, Gemini ou Claude AI directement depuis l'application.
- **üìö Biblioth√®que de Prompts** : Une collection de prompts pr√©d√©finis et personnalisables pour des t√¢ches complexes : analyse d'architecture, audit de s√©curit√©, planification de fonctionnalit√©s, etc.
- **üîÑ Int√©gration `git diff`** : Analysez en un clic les modifications en attente (`--staged`) pour g√©n√©rer des messages de commit ou obtenir des revues de code.
- **üìÑ Export Multi-format** : Exportez vos conversations au format Markdown, DOCX ou PDF.

## ‚öôÔ∏è Installation

### Pr√©requis
- Windows (l'application est optimis√©e pour Windows via `run.bat`)
- [Miniconda](https://docs.conda.io/en/latest/miniconda.html) ou Anaconda

### √âtapes d'installation
1.  Clonez le d√©p√¥t :
    ```bash
    git clone https://github.com/Astral0/code-to-llm.git
    cd code-to-llm
    ```
2.  Le script `run.bat` est con√ßu pour automatiser la configuration. Il va :
    - Chercher votre installation Conda.
    - V√©rifier et activer l'environnement `code2llm` (il doit exister).
    - Lancer l'application.

    Si c'est la premi√®re fois, cr√©ez l'environnement Conda :
    ```bash
    conda create -n code2llm python=3.9
    conda activate code2llm
    pip install -r requirements.txt
    ```
3.  **Configuration Essentielle** :
    Copiez `config.ini.template` vers `config.ini` et configurez-le. Pour utiliser la Toolbox, la section `[LLMServer]` est requise :
    ```ini
    [LLMServer]
    # URL de l'API de votre LLM.
    # Ex: https://api.openai.com/v1 ou http://localhost:11434 pour Ollama
    url = YOUR_LLM_API_URL_HERE
    
    # Votre cl√© API (requise pour OpenAI, non n√©cessaire pour Ollama local)
    apikey = YOUR_LLM_API_KEY_HERE
    
    # Mod√®le √† utiliser
    # Ex: gpt-4-turbo-preview, gpt-3.5-turbo, llama3, codellama
    model = YOUR_LLM_MODEL_HERE
    
    # Type d'API : 'openai' ou 'ollama'
    api_type = openai
    
    # Activer l'int√©gration LLM dans la Toolbox
    enabled = true
    
    # Activer le streaming des r√©ponses pour le chat
    stream_response = true
    
    # Param√®tres optionnels pour contr√¥ler la g√©n√©ration (d√©commentez si n√©cessaire)
    # temperature = 0.7  # Contr√¥le la cr√©ativit√© (0.0 = d√©terministe, 1.0 = tr√®s cr√©atif)
    # max_tokens = 4096  # Nombre maximum de tokens pour la r√©ponse
    ```
4.  Lancez l'application en double-cliquant sur **`run.bat`**.

## üöÄ Guide d'Utilisation

1.  **Scanner un Projet** :
    - Lancez l'application via `run.bat`.
    - Cliquez sur **"S√©lectionner un r√©pertoire"** pour ouvrir la bo√Æte de dialogue native.
    - Choisissez votre projet et cliquez sur **"Scanner le r√©pertoire"**.
2.  **S√©lectionner les Fichiers** :
    - L'arbre des fichiers de votre projet (filtr√©s) appara√Æt.
    - Si vous avez d√©j√† travaill√© sur ce projet, une section **"Session Pr√©c√©dente D√©tect√©e"** appara√Æt :
        - Cliquez sur le bouton **"Restaurer la s√©lection pr√©c√©dente"** pour r√©appliquer votre s√©lection de fichiers.
        - Les **nouveaux fichiers** ajout√©s depuis votre derni√®re session sont mis en √©vidence dans une section d√©di√©e.
    - Cochez les fichiers et dossiers que vous souhaitez inclure dans le contexte.
3.  **G√©n√©rer le Contexte** :
    - Dans la section 3, ajoutez des instructions initiales au LLM si n√©cessaire.
    - Choisissez un mode de **Compression** si besoin (Mode Compact ou R√©sum√© par IA).
    - Cliquez sur **"Generate context for selection"**.
4.  **Interagir avec l'IA** :
    - Le contexte Markdown est g√©n√©r√© et affich√©.
    - Cliquez sur **"Ouvrir la Toolbox"**.
    - Choisissez votre mode (`API` ou `Navigateur Int√©gr√©`).
    - Dans la Toolbox, cliquez sur **"Importer le contexte du projet"**.
    - Vous pouvez maintenant utiliser les prompts ou discuter avec l'IA √† propos de votre code.

## üíæ Gestion Avanc√©e des Conversations

La Toolbox va au-del√† d'un simple chat en proposant un syst√®me de sauvegarde complet, transformant chaque session en une "capsule temporelle" r√©utilisable.

### üéØ G√©n√©ration Automatique de Titres par IA
Lors de la sauvegarde d'une conversation, vous pouvez :
- **Saisir manuellement** un titre descriptif
- **Utiliser la baguette magique** ü™Ñ pour obtenir une suggestion de titre g√©n√©r√©e par l'IA qui analyse le contenu de votre conversation
- L'IA effectue une **analyse s√©mantique** en ignorant les blocs de code pour se concentrer sur le sujet principal de la discussion

### "Capsules Temporelles" de Conversation
Chaque sauvegarde n'enregistre pas seulement l'historique des messages, mais aussi **l'int√©gralit√© du contexte du projet** tel qu'il √©tait au moment de la conversation. Cela vous permet de reprendre une analyse ou un d√©veloppement exactement l√† o√π vous l'aviez laiss√©, m√™me si le code source a chang√© depuis.

### Syst√®me de Verrouillage Multi-Instance
Pour garantir l'int√©grit√© de vos donn√©es, un syst√®me de verrouillage intelligent est int√©gr√© :
-   **Verrouillage Automatique** : Lorsque vous chargez ou sauvegardez une conversation, elle est automatiquement "verrouill√©e" par votre session.
-   **Pr√©vention des Conflits** : Si vous ouvrez la m√™me conversation dans une autre fen√™tre, elle appara√Ætra comme verrouill√©e, vous emp√™chant de la modifier et d'√©craser accidentellement des donn√©es.
-   **Information Visuelle** : Des ic√¥nes claires indiquent le statut de chaque conversation (verrouill√©e par vous, par un autre, ou libre).
-   **Gestion des Verrous** : Vous pouvez lib√©rer manuellement vos verrous ou forcer la lib√©ration d'un verrou orphelin si une instance de l'application s'est mal ferm√©e.

### Fonctionnalit√©s de l'Interface
Depuis la barre lat√©rale de la Toolbox, vous pouvez :
-   **Sauvegarder** la conversation actuelle.
-   **Charger** une conversation existante pour restaurer l'historique et le contexte.
-   **Dupliquer** une conversation pour explorer une nouvelle piste d'analyse sans alt√©rer l'original.
-   **Renommer** vos conversations pour mieux les organiser.
-   **Supprimer** les sessions dont vous n'avez plus besoin.

## üèóÔ∏è Architecture Technique

Le projet adopte une architecture orient√©e services pour garantir la modularit√©, la testabilit√© et la clart√©. La classe `Api` dans `main_desktop.py` sert de **fa√ßade**, orchestrant les appels aux diff√©rents services backend.

- **`main_desktop.py` (API Fa√ßade)** : Point d'entr√©e de l'application de bureau. G√®re les fen√™tres (`pywebview`), expose les m√©thodes Python au JavaScript et orchestre les services.
- **`web_server.py` (Serveur Flask)** : Serveur local qui rend les templates HTML et fournit des endpoints API (principalement pour le mode web historique, mais utilis√© par la fen√™tre pywebview).
- **`services/` (Logique M√©tier)** :
    - `FileService` : G√®re le scan des syst√®mes de fichiers, l'application des r√®gles `.gitignore`, le filtrage des fichiers binaires et le **masquage des secrets**.
    - `ContextBuilderService` : Assemble le contexte final en Markdown, g√©n√®re l'arbre de fichiers et estime la taille en tokens.
    - `LlmApiService` : G√®re toute la communication avec les API LLM (OpenAI, Ollama), y compris la gestion du streaming et une strat√©gie de `retry` intelligente.
    - `GitService` : Ex√©cute les commandes Git, comme `git diff --staged`.
    - `ExportService` : G√®re l'export des conversations en Markdown, DOCX et PDF.
- **`pywebview_driver.py` (Pilote Personnalis√©)** : Un driver l√©ger imitant l'API de Selenium pour interagir par programmation avec le contenu de la fen√™tre de navigateur int√©gr√©e.
- **`tests/` (Suite de Tests)** : Le projet inclut des tests unitaires (`pytest`) pour chaque service ainsi que des tests d'int√©gration pour la fa√ßade `Api`, garantissant la robustesse de l'application.

## üîß Configuration Avanc√©e

Le fichier `config.ini` permet une personnalisation fine :

### Configuration de la G√©n√©ration de Titres par IA (`[TitleGeneratorLLM]`)

Configuration optionnelle pour personnaliser la g√©n√©ration automatique de titres. Si cette section est absente, le syst√®me utilise automatiquement la configuration de `[LLMServer]`.

```ini
[TitleGeneratorLLM]
# Activer/d√©sactiver la fonctionnalit√©
enabled = true

# Configuration sp√©cifique (optionnelle, utilise LLMServer si non d√©finie)
# url = YOUR_TITLE_LLM_API_URL_HERE
# apikey = YOUR_TITLE_LLM_API_KEY_HERE
# model = gpt-3.5-turbo  # Mod√®le plus l√©ger pour la g√©n√©ration de titres

# Prompt personnalis√© pour la g√©n√©ration
title_prompt = G√©n√®re un titre court et descriptif...

# Param√®tres de g√©n√©ration
max_title_length = 100
timeout_seconds = 15
# temperature = 0.5  # Plus d√©terministe pour les titres
```

### Exclusion de Fichiers (`[FileExclusion]`)

Excluez des fichiers ou des motifs de la s√©lection.

```ini
[FileExclusion]
# Fichiers sp√©cifiques √† exclure, s√©par√©s par des virgules
file_blacklist = .DS_Store, Thumbs.db, yarn.lock
# Motifs √† exclure (supporte * et ?)
pattern_blacklist = *.min.js, *-lock.json, *.pyc
```

### D√©tection Binaire (`[BinaryDetection]`)

Affinez la d√©tection des fichiers binaires.

```ini
[BinaryDetection]
# Extensions imm√©diatement rejet√©es
extension_blacklist = .png, .jpg, .exe, .dll, .so, .pdf, .zip, .woff
# Extensions imm√©diatement accept√©es sans analyse de contenu
extension_whitelist = .py, .js, .html, .css, .json, .md, .txt, .sh
```

## ü§ù Contribution

Les contributions sont les bienvenues ! Si vous souhaitez am√©liorer l'application, n'h√©sitez pas √† forker le d√©p√¥t et √† soumettre une Pull Request.

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.
