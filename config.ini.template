[Debug]
# Active le mode debug pour pywebview et les logs détaillés
debug = false

[Instructions]
instruction1_text = Ne fais rien, attends mes instructions.
instruction2_text = Si des modifications du code source est nécessaire, tu dois présenter ta réponse sous la forme d'un fichier patch Linux. Considère que le fichier patch a été lancé depuis le répertoire du code-to-llm.

[LLMServer]
url = YOUR_LLM_API_URL_HERE
apikey = YOUR_LLM_API_KEY_HERE
model = YOUR_LLM_MODEL_HERE
api_type = openai # Can be 'openai' or 'ollama'
enabled = false
stream_response = true
ssl_verify = true # Set to false to disable SSL certificate verification (use with caution)

[SummarizerLLM]
# LLM pour le RESUME du code (compression "lossy")
# Peut être différent du LLM de chat. Ex: un modèle spécialisé en code.
url = http://localhost:11434 # Pointe vers votre instance Ollama locale
apikey = YOUR_LLM_API_KEY_HERE
model = llama3:70b # Modèle puissant pour le résumé
api_type = ollama
enabled = true # Doit être activé pour que la fonction de résumé fonctionne
summarizer_prompt = Tu es un expert en analyse de code source. Analyse le fichier `{file_path}` et fournis un résumé concis au format JSON. Le format de sortie doit être EXCLUSIVEMENT un objet JSON valide.\n\nInstructions pour chaque clé :\n- "role": Décris en une phrase le rôle principal du fichier (ex: "Serveur web Flask pour l'application principale", "Logique frontend pour l'interaction utilisateur", "Module de construction de contexte LLM").\n- "public_interface": Liste les fonctions, classes, ou endpoints API principaux qui sont destinés à être utilisés par d'autres parties du code. Sois concis. Pour du HTML, liste les sections principales. Pour du CSS, les classes majeures.\n- "dependencies": Liste les modules ou fichiers importés qui sont essentiels à ce fichier.\n\nCode du fichier `{file_path}`:\n---\n{content}\n---
summarizer_timeout_seconds = 300
summarizer_max_workers = 2

[chatgpt]
login_url = https://chat.openai.com
prompt_textarea_selector = #prompt-textarea
submit_button_selector = [data-testid="send-button"]

[gemini]
login_url = https://gemini.google.com
prompt_textarea_selector = div.ql-editor[data-placeholder^="Demandez"]
submit_button_selector = button.send-button

[Tokens]
# Optional: API key for token calculation services if you use one

[Git]
# Chemin vers l'exécutable git (optionnel - laissez vide pour utiliser git du PATH)
# Exemple Windows: C:\Program Files\Git\bin\git.exe
# Exemple Linux/Mac: /usr/bin/git
executable_path = 

[BinaryDetection]
# Fichiers immédiatement rejetés (séparés par des virgules)
extension_blacklist = .png, .jpg, .jpeg, .gif, .bmp, .ico, .exe, .dll, .so, .pdf, .zip, .gz, .rar, .mp3, .mp4, .avi, .mov, .woff, .woff2, .eot, .ttf, .otf, .class, .jar, .pyc, .bin, .dat, .dmg, .iso, .msi, .cjs

# Fichiers immédiatement acceptés sans analyse de contenu (séparés par des virgules)
extension_whitelist = .py, .js, .html, .css, .json, .md, .txt, .sh, .yml, .yaml, .xml, .ini, .cfg, .conf, .rst, .ts, .jsx, .tsx, .toml, .sql

[FileExclusion]
# Fichiers spécifiques à exclure (séparés par des virgules)
# Ces fichiers sont utiles dans Git mais pas pour le contexte LLM
file_blacklist = .pnp.cjs, package-lock.json, yarn.lock, .DS_Store, Thumbs.db

# Patterns à exclure (supporte * et ?)
# Exemples: *.min.js, *-lock.json, test-*.js
pattern_blacklist = *.min.js, *.min.css, *-lock.json, *.map
